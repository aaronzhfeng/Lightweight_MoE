epoch,loss,grad_norm,learning_rate
1.0,4.5996,7.6050705909729,4.766666666666667e-05
2.0,3.9098,14.37641716003418,4.5333333333333335e-05
3.0,3.1274,24.89023780822754,4.2833333333333335e-05
4.0,2.3312,20.054271697998047,4.0333333333333336e-05
5.0,1.7353,17.120088577270508,3.7833333333333336e-05
6.0,1.2762,15.643247604370117,3.5333333333333336e-05
7.0,0.9127,10.328717231750488,3.283333333333333e-05
8.0,0.7234,15.651459693908691,3.0333333333333337e-05
9.0,0.5282,13.165779113769531,2.7833333333333333e-05
10.0,0.4507,11.972829818725586,2.5333333333333337e-05
11.0,0.3828,16.678470611572266,2.2833333333333334e-05
12.0,0.3331,5.218963623046875,2.0333333333333334e-05
13.0,0.2562,0.5626490116119385,1.7833333333333334e-05
14.0,0.2835,10.92097282409668,1.5333333333333334e-05
15.0,0.2563,13.844746589660645,1.2833333333333333e-05
16.0,0.2321,5.364108562469482,1.0333333333333333e-05
17.0,0.2085,4.911080360412598,7.833333333333333e-06
18.0,0.1866,0.8569371700286865,5.333333333333334e-06
19.0,0.2,4.328950881958008,2.8333333333333335e-06
20.0,0.1889,8.586971282958984,3.3333333333333335e-07
